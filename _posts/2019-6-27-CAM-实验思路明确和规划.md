---
layout:     post
title:      "CAM 实验思路明确和规划"
subtitle:   " \"暑假实验正式开始\""
date:       2019-6-27 13:00:00
author:     "jack"
header-img: "img/post-bg-road1.jpg"
catalog: true
tags:
    - 可解释性

---

### 实验思路总结

为了增强可解释性，我们通过对目前可解释性衡量标准的学习（If two data points are nearly equivalent, then the explanations of their predictions should also be nearly equivalent），认为好的解释性网络应该具有

1. 输入两个同类，但差异很大的图片，输出结果尽可能相似
2. 输入两个不同类，差异不大的图片，输出结果尽可能不相似

 这个结果的衡量，一方面是output accuracy，另一方面就是`topconv`上面进行样本度量。将多维度的GAP看成一个特征向量，通过度量得到量化的指标，来影响网络的训练迭代。

而且我们发现GAP实际上丢失了 topconv 各个通道上面的关联性，而我们认为这些关系也很重要。

我们的方法是将这些值看成一个特征向量，目前是通过聚类的方法来度量，然后将聚类得到了对应n个类的指标，直接跟softmax之后的概率相乘，来预测类标。这样迭代训练得到一个更好的网络。

![](https://jackyanghc-picture.oss-cn-beijing.aliyuncs.com/多层神经网络图解 (1).png)

#### 实验计划

1. 把cam原文的数据集跑一遍，将结果进行比较
2. 在mnist 数据集上面进行实验，看看效果。

