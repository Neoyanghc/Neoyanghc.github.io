---
layout:     post
title:      "19.4.11_组会问题记录与学习"
subtitle:   " \"找问题，研究生学习方法，网络复现\""
date:       2019-04-11 13:00:00
author:     "jack"
header-img: "img/post-bg-forest.jpg"
catalog: true
tags:
    - 可解释性
    - 组会记录
    - 深度学习
---

## 4.11 机器学习与认知计算所第三次组会问题记录

> "第一次发言，好紧张啊"

### 1. 前言

没想到，这才第三次组会一个月的时间，自己就能够从旁听生到讲台上发表自己的意见

兴奋，又紧张吧。一直在准备自己要讲啥，所以前面学长学姐在讲什么也没听清楚，😭哈哈哈

所以这次主要还是对自己发言的问题进行总结，然后对一些问题进行回答

### 2.可解释性对比思路问题

其实刚开始想到这个，自己还觉得很不错，尤其是对应的思路和解决方案，但是后面通过和学长讨论，觉得这个题目又不太好，这次组会上老师又给我理了一遍，让我又觉得信心满满了

在此，对整个这一个月的思路进行一个总结

+ 第一阶段：**对比**

  + 在output 和output上面对比，
  + 直接通过概率来衡量网络的好坏

+ 第二阶段，

  + 这一阶段就是想法比较多

  - input 和 output 之间也可以对比
  - 觉得事后解释性，由于类之间的稀疏程度，函数很难选，以及是否要进进行与训练
  - 加loss的事中解释性
  - 各种度量方法的调研，以及来自DDC的inspiration

+ 第三阶段，

  + 现在的想法觉得其实两个应该都可以进行下去  

  + 针对事后解释性，先对MMD在GAP上面进行一个实验
  + 对度量方法，可以先对现有方法直接实验
  + 事中解释性，是针对loss的可以讲度量方法挑选的差不多的进行网络的搭建

![](http://jackyanghc-picture.oss-cn-beijing.aliyuncs.com/007bgNxTly1g24pncuzimj31k00w0aj8.jpg%29)

### 3. 可解释性问题解决总结

#### 3.1 是否要对比input 和 output 之间的差距

**不用**。无论是在事后解释性和事中解释性，这样做都会将网络的功能进行退化。

如果要做这个对比，也可以是逐层对比。

#### 3.2 pre-train 是否会带来更复杂的解释性

**不会**。对应的度量方法都有对应的方法论，我们在神经网络进行解释。

可以不去管度量方法的解释，那方面其实又对应的推到等

#### 3.3  不同类之间的差距理解

毋庸置疑，不同类之间的差距当然会有很大的差别

但是我们可以通过子空间投影对这些差距进行处理，将其映射到不用的空间中去来解决

